# Machine Translation
Seq2seq model for Neural Machine Translation (NMT) from Spanish to English implemented in Keras

### Aproach :  
This task is performed using a  encoder-decoder LSTM model. In this architecture, the input sequence is encoded by a front-end model called the encoder then decoded word by word by a backend model called the decoder.
![alt text](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Plot-of-Model-Graph-for-NMT.png "Sample Model Architecture")

### Dataset : 
The dataset was selected from the Manythings.org website that created a database of translations ( from the Tatoeba Project ) to be used with the ANKI flash card software

[Source Website](http://www.manythings.org/anki/)
(http://www.manythings.org/anki/spa-eng.zip "Click to Dwonload Dataset" )[Link to Dataset]
